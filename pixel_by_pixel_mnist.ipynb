{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-28T10:17:59.182600Z",
     "iopub.status.busy": "2021-01-28T10:17:59.181973Z",
     "iopub.status.idle": "2021-01-28T10:17:59.214640Z",
     "shell.execute_reply": "2021-01-28T10:17:59.214052Z"
    },
    "papermill": {
     "duration": 0.051599,
     "end_time": "2021-01-28T10:17:59.214736",
     "exception": false,
     "start_time": "2021-01-28T10:17:59.163137",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torch.utils.data import Subset, DataLoader\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import tqdm\n",
    "from tqdm import tqdm as tqdm\n",
    "from models import *\n",
    "%matplotlib inline\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2021-01-28T10:17:59.253753Z",
     "iopub.status.busy": "2021-01-28T10:17:59.253048Z",
     "iopub.status.idle": "2021-01-28T10:17:59.256441Z",
     "shell.execute_reply": "2021-01-28T10:17:59.256925Z"
    },
    "papermill": {
     "duration": 0.03087,
     "end_time": "2021-01-28T10:17:59.257035",
     "exception": false,
     "start_time": "2021-01-28T10:17:59.226165",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = torchvision.datasets.MNIST('./tmp', train=True, download=False,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ]))\n",
    "\n",
    "dataset_test = torchvision.datasets.MNIST('./tmp', train=False, download=False,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-28T10:17:59.364099Z",
     "iopub.status.busy": "2021-01-28T10:17:59.363277Z",
     "iopub.status.idle": "2021-01-28T10:17:59.368255Z",
     "shell.execute_reply": "2021-01-28T10:17:59.367752Z"
    },
    "papermill": {
     "duration": 0.029595,
     "end_time": "2021-01-28T10:17:59.368345",
     "exception": false,
     "start_time": "2021-01-28T10:17:59.338750",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size=128\n",
    "\n",
    "# Split the indices in a stratified way\n",
    "indices = np.arange(len(dataset))\n",
    "\n",
    "train_indices = indices[0:int(np.floor(60000/batch_size))*batch_size]\n",
    "test_indices = indices[0:int(np.floor(10000/batch_size))*batch_size]\n",
    "\n",
    "train_indices = indices[0:int(np.floor(200/batch_size))*batch_size]\n",
    "test_indices = indices[0:int(np.floor(200/batch_size))*batch_size]\n",
    "\n",
    "# Warp into Subsets and DataLoaders\n",
    "train_dataset = Subset(dataset, train_indices)\n",
    "test_dataset = Subset(dataset_test, test_indices)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, shuffle=True, num_workers=2, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_dataset, shuffle=False, num_workers=2, batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-28T10:17:59.403590Z",
     "iopub.status.busy": "2021-01-28T10:17:59.402692Z",
     "iopub.status.idle": "2021-01-28T10:17:59.420763Z",
     "shell.execute_reply": "2021-01-28T10:17:59.420255Z"
    },
    "papermill": {
     "duration": 0.039342,
     "end_time": "2021-01-28T10:17:59.420863",
     "exception": false,
     "start_time": "2021-01-28T10:17:59.381521",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Functions for one batch update of the network\n",
    "\n",
    "def train_step(hidden_size, input_tensor, target):\n",
    "    hidden_bottom_0 = torch.zeros(1,hidden_size).to(device)\n",
    "    hidden_top_0 = torch.zeros(1,hidden_size).to(device)\n",
    "    frnn.zero_grad()\n",
    "\n",
    "    for i in range(input_tensor.shape[-1]):\n",
    "    #for i in range(300):\n",
    "        out, hidden_bottom_0, hidden_top_0 = frnn(input_tensor[:,i:i+1], hidden_bottom_0.to(device), hidden_top_0.to(device))\n",
    "        if i==input_tensor.shape[-1]-1:\n",
    "        #if i == 1:\n",
    "            loss = criterion(out, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            return loss.item(), out\n",
    "        \n",
    "        \n",
    "def val_step(hidden_size, input_tensor, target):\n",
    "    hidden_bottom_0 = torch.zeros(1,hidden_size).to(device)\n",
    "    hidden_top_0 = torch.zeros(1,hidden_size).to(device)\n",
    "\n",
    "    for i in range(input_tensor.shape[-1]):\n",
    "        out, hidden_bottom_0, hidden_top_0 = frnn(input_tensor[:,i:i+1], hidden_bottom_0.to(device), hidden_top_0.to(device))\n",
    "        if i==input_tensor.shape[-1]-1:\n",
    "            loss = criterion(out, target)\n",
    "            return loss.item(), out\n",
    "        \n",
    "        \n",
    "def get_accuracy(logit, target, batch_size):\n",
    "    ''' Obtain accuracy for training round '''\n",
    "    corrects = (torch.max(logit, 1)[1].view(target.size()).data == target.data).sum()\n",
    "    accuracy = 100.0 * corrects/batch_size\n",
    "    return accuracy.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-28T10:17:59.459002Z",
     "iopub.status.busy": "2021-01-28T10:17:59.451989Z",
     "iopub.status.idle": "2021-01-28T10:17:59.462694Z",
     "shell.execute_reply": "2021-01-28T10:17:59.462179Z"
    },
    "papermill": {
     "duration": 0.02822,
     "end_time": "2021-01-28T10:17:59.462806",
     "exception": false,
     "start_time": "2021-01-28T10:17:59.434586",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device = torch.device(\"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter Settings\n",
    "\n",
    "epochs = 150\n",
    "hidden_size = 128\n",
    "gamma = 0.15\n",
    "epsilon = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#device=\"cpu\"\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-28T10:17:59.765892Z",
     "iopub.status.busy": "2021-01-28T10:17:59.752921Z",
     "iopub.status.idle": "2021-01-28T10:17:59.768854Z",
     "shell.execute_reply": "2021-01-28T10:17:59.769313Z"
    },
    "papermill": {
     "duration": 0.044937,
     "end_time": "2021-01-28T10:17:59.769445",
     "exception": false,
     "start_time": "2021-01-28T10:17:59.724508",
     "status": "completed"
    },
    "scrolled": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "## MAIN TRAINING LOOP ## \n",
    "\n",
    "\n",
    "# Select Model\n",
    "frnn = FRNN_AS_SC(1,hidden_size,10, device, epsilon=epsilon, gamma=gamma)\n",
    "#frnn = TLRNN_AS_SC(1,hidden_size,10, device, epsilon=epsilon, gamma=gamma)\n",
    "#frnn = FRNN_SC(1,hidden_size,10, device, epsilon=epsilon, gamma=gamma)\n",
    "\n",
    "\n",
    "\n",
    "frnn.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer= torch.optim.Adagrad(frnn.parameters(), lr=1e-2)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, patience=10, verbose=True, factor=0.1)\n",
    "\n",
    "\n",
    "#Lists to gather data\n",
    "losses = []\n",
    "accuracys = []\n",
    "val_losses = []\n",
    "val_accuracys = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    epoch_accuracys = []\n",
    "    epoch_losses = []\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data = data.reshape(batch_size,-1)\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "    \n",
    "        loss, pred = train_step(hidden_size, data, target)\n",
    "\n",
    "        epoch_losses.append(loss)\n",
    "        acc = get_accuracy(pred, target, batch_size)\n",
    "        epoch_accuracys.append(acc)\n",
    "    \n",
    "    \n",
    "\n",
    "    losses.append(np.mean(epoch_losses))\n",
    "    accuracys.append(np.mean(epoch_accuracys))\n",
    "    print('Epoch:  %d | Loss: %.4f | Train Accuracy: %.2f' \n",
    "      %(epoch, np.mean(epoch_losses) , np.mean(epoch_accuracys)))\n",
    "    \n",
    "    epoch_accuracys = []\n",
    "    epoch_losses = []\n",
    "    \n",
    "\n",
    "\n",
    "    #Performing Evaluation\n",
    "    for batch_idx, (data, target) in enumerate(test_loader):\n",
    "        data = data.reshape(batch_size,-1)\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "\n",
    "        loss, pred = val_step(hidden_size, data, target)\n",
    "\n",
    "        epoch_losses.append(loss)\n",
    "        acc = get_accuracy(pred, target, batch_size)\n",
    "        epoch_accuracys.append(acc)\n",
    "        \n",
    "    #Save best model only\n",
    "    if(epoch > 1):\n",
    "        if(np.mean(epoch_losses) < np.min(val_losses)):\n",
    "            path = \"model.pt\"\n",
    "            torch.save(frnn.state_dict(), path)\n",
    "        \n",
    "    val_losses.append(np.mean(epoch_losses))\n",
    "    val_accuracys.append(np.mean(epoch_accuracys))\n",
    "\n",
    "    \n",
    "\n",
    "    print('Epoch:  %d | Val-Loss: %.4f | Val Accuracy: %.2f' \n",
    "      %(epoch, np.mean(epoch_losses) , np.mean(epoch_accuracys)))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "papermill": {
   "duration": 5.426743,
   "end_time": "2021-01-28T10:17:59.958255",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-01-28T10:17:54.531512",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
