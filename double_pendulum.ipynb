{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from numpy import sin, cos\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.integrate as integrate\n",
    "import matplotlib.animation as animation\n",
    "import random\n",
    "import tqdm\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import tqdm\n",
    "import timeit\n",
    "import random\n",
    "from torch.utils.data import Subset, DataLoader, Dataset\n",
    "from models import *\n",
    "#from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Pendulum Parameters and Equation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = 9.8  # acceleration due to gravity, in m/s^2\n",
    "L1 = 1.0  # length of pendulum 1 in m\n",
    "L2 = 1.0  # length of pendulum 2 in m\n",
    "M1 = 1.0  # mass of pendulum 1 in kg\n",
    "M2 = 1.0  # mass of pendulum 2 in kg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Derivatives for the double pendulum\n",
    "def derivs(state, t):\n",
    "\n",
    "    dydx = np.zeros_like(state)\n",
    "    dydx[0] = state[1]\n",
    "\n",
    "    del_ = state[2] - state[0]\n",
    "    den1 = (M1 + M2)*L1 - M2*L1*cos(del_)*cos(del_)\n",
    "    dydx[1] = (M2*L1*state[1]*state[1]*sin(del_)*cos(del_) +\n",
    "               M2*G*sin(state[2])*cos(del_) +\n",
    "               M2*L2*state[3]*state[3]*sin(del_) -\n",
    "               (M1 + M2)*G*sin(state[0]))/den1\n",
    "\n",
    "    dydx[2] = state[3]\n",
    "\n",
    "    den2 = (L2/L1)*den1\n",
    "    dydx[3] = (-M2*L2*state[3]*state[3]*sin(del_)*cos(del_) +\n",
    "               (M1 + M2)*G*sin(state[0])*cos(del_) -\n",
    "               (M1 + M2)*L1*state[1]*state[1]*sin(del_) -\n",
    "               (M1 + M2)*G*sin(state[2]))/den2\n",
    "\n",
    "    return dydx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = []\n",
    "\n",
    "for i in tqdm.tqdm(range(100)):\n",
    "    #Time to integrate solution\n",
    "    dt = 0.1\n",
    "    t = np.arange(0.0, 3, dt)\n",
    "\n",
    "    #Initial values\n",
    "    th1 = np.random.uniform(-90,90)\n",
    "    w1 = np.random.uniform(-90,90)\n",
    "    th2 = np.random.uniform(-90,90)\n",
    "    w2 = np.random.uniform(-90,90)\n",
    "\n",
    "    #Integrate\n",
    "    # initial state\n",
    "    state = np.radians([th1, w1, th2, w2])\n",
    "\n",
    "    # integrate your ODE using scipy.integrate.\n",
    "    y = integrate.odeint(derivs, state, t)\n",
    "    Y.append(y)\n",
    "\n",
    "#     #Get euclidean values from solution\n",
    "#     x1 = L1*sin(y[:, 0])\n",
    "#     y1 = -L1*cos(y[:, 0])\n",
    "\n",
    "#     x2 = L2*sin(y[:, 2]) + x1\n",
    "#     y2 = -L2*cos(y[:, 2]) + y1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"90angle_90veloc_1k_3s.data\", \"wb\") as f:\n",
    "    pickle.dump(Y, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Trajectories and create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"90angle_90veloc_1k_3s.data\", \"rb\") as f:\n",
    "    Y = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PendulumDataset(Dataset):\n",
    "\n",
    "    def __init__(self, dataset_list):\n",
    "        self.label_array = dataset_list\n",
    "    def __getitem__(self, idx):\n",
    "        return self.label_array[idx]\n",
    "    def __len__(self):\n",
    "        return len(self.label_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = PendulumDataset(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset, testset = torch.utils.data.random_split(dataset, [90, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(trainset, batch_size=8, shuffle=False)\n",
    "dataloader_test = DataLoader(testset, batch_size=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Train Steps to work with Dataloader\n",
    "\n",
    "def train_step(y, hidden_size, net):\n",
    "    \"\"\"\n",
    "    x: List of float values of the time series\n",
    "    y: List of float values of the target time series\n",
    "    hidden_size: hidden size of the recurrent layers\n",
    "    \"\"\"\n",
    "    net.zero_grad()\n",
    "    loss = 0\n",
    "    top_t0 = torch.ones(1, hidden_size).to(device)\n",
    "    bottom_t0 = torch.ones(1, hidden_size).to(device)\n",
    "    inp = torch.ones(1,4).to(device)\n",
    "\n",
    "    \n",
    "    for i in range(len(y[0])-1):\n",
    "        #out, bottom_t0, top_t0 = net(out_d, bottom_t0, top_t0)\n",
    "        if i==0:\n",
    "            out, bottom_t0, top_t0 = net(y[:,i,:].float().to(device), bottom_t0.to(device), top_t0.to(device))\n",
    "        else:\n",
    "            out, bottom_t0, top_t0 = net(inp, bottom_t0, top_t0)\n",
    "            #out, bottom_t0, top_t0 = net(y[:,i,:].float(), bottom_t0, top_t0)\n",
    "\n",
    "\n",
    "        l = criterion(out, torch.tensor(y[:,i+1,:]).float())\n",
    "        loss += l\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return out, loss.item()\n",
    "\n",
    "def val_step(y, hidden_size, net):\n",
    "    \"\"\"\n",
    "    x: List of float values of the time series\n",
    "    y: List of float values of the target time series\n",
    "    hidden_size: hidden size of the recurrent layers\n",
    "    \"\"\"\n",
    "    net.zero_grad()\n",
    "    top_t0 = torch.ones(1, hidden_size).to(device)\n",
    "    bottom_t0 = torch.ones(1, hidden_size).to(device)\n",
    "    inp = torch.ones(1,4).to(device)\n",
    "\n",
    "\n",
    "    loss = 0\n",
    "    Outs = []\n",
    "    for i in range(len(y[0])-1):\n",
    "        if i==0:\n",
    "            out, bottom_t0, top_t0 = net(y[:,i,:].float(), bottom_t0, top_t0)\n",
    "        else:\n",
    "            out, bottom_t0, top_t0 = net(inp, bottom_t0, top_t0)\n",
    "            #out, bottom_t0, top_t0 = net(y[:,i,:].float(), bottom_t0, top_t0)\n",
    "\n",
    "\n",
    "        l = criterion(out, torch.tensor(y[:, i+1, :]).float())\n",
    "        loss += l\n",
    "        Outs.append(out.cpu().detach().numpy())\n",
    "    return Outs, loss.item()\n",
    "\n",
    "\n",
    "def train_step_ARNN(y, hidden_size, net):\n",
    "    \"\"\"\n",
    "    x: List of float values of the time series\n",
    "    y: List of float values of the target time series\n",
    "    hidden_size: hidden size of the recurrent layers\n",
    "    \"\"\"\n",
    "    net.zero_grad()\n",
    "    loss = 0\n",
    "    top_t0 = torch.ones(1, hidden_size).to(device)\n",
    "    bottom_t0 = torch.ones(1, hidden_size).to(device)\n",
    "    inp = torch.ones(1,4).to(device)\n",
    "\n",
    "    \n",
    "    for i in range(len(y[0])-1):\n",
    "        #out, bottom_t0, top_t0 = net(out_d, bottom_t0, top_t0)\n",
    "        if i==0:\n",
    "            out, bottom_t0= net(y[:,i,:].float().to(device), bottom_t0.to(device))\n",
    "        else:\n",
    "            out, bottom_t0= net(inp, bottom_t0)\n",
    "            #out, bottom_t0, top_t0 = net(y[:,i,:].float(), bottom_t0, top_t0)\n",
    "\n",
    "\n",
    "        l = criterion(out, torch.tensor(y[:,i+1,:]).float())\n",
    "        loss += l\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return out, loss.item()\n",
    "\n",
    "def val_step_ARNN(y, hidden_size, net):\n",
    "    \"\"\"\n",
    "    x: List of float values of the time series\n",
    "    y: List of float values of the target time series\n",
    "    hidden_size: hidden size of the recurrent layers\n",
    "    \"\"\"\n",
    "    net.zero_grad()\n",
    "    top_t0 = torch.ones(1, hidden_size).to(device)\n",
    "    bottom_t0 = torch.ones(1, hidden_size).to(device)\n",
    "    inp = torch.ones(1,4).to(device)\n",
    "\n",
    "\n",
    "    loss = 0\n",
    "    Outs = []\n",
    "    for i in range(len(y[0])-1):\n",
    "        if i==0:\n",
    "            out, bottom_t0= net(y[:,i,:].float(), bottom_t0)\n",
    "        else:\n",
    "            out, bottom_t0 = net(inp, bottom_t0)\n",
    "            #out, bottom_t0, top_t0 = net(y[:,i,:].float(), bottom_t0, top_t0)\n",
    "\n",
    "\n",
    "        l = criterion(out, torch.tensor(y[:, i+1, :]).float())\n",
    "        loss += l\n",
    "        Outs.append(out.cpu().detach().numpy())\n",
    "    return Outs, loss.item()\n",
    "\n",
    "def test_step(y, hidden_size, net, leng):\n",
    "    \"\"\"\n",
    "    y: Initial values for the pendulum \n",
    "    hidden_size: hidden size of the recurrent layers\n",
    "    leng: How long to predict(in 0.1s unit)\n",
    "    \"\"\"\n",
    "    net.zero_grad()\n",
    "    top_t0 = torch.ones(1, hidden_size)\n",
    "    bottom_t0 = torch.ones(1, hidden_size)\n",
    "    inp = torch.ones(1,4)\n",
    "\n",
    "\n",
    "    loss = 0\n",
    "    Outs = []\n",
    "    for i in range(leng):\n",
    "        if i==0:\n",
    "            out, bottom_t0, top_t0 = net(y, bottom_t0, top_t0)\n",
    "        else:\n",
    "            out, bottom_t0, top_t0 = net(inp, bottom_t0, top_t0)\n",
    "            #out, bottom_t0, top_t0 = net(y[:,i,:].float(), bottom_t0, top_t0)\n",
    "\n",
    "\n",
    "        Outs.append(out.detach().numpy())\n",
    "    return Outs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training for FRNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Train Procedure\n",
    "\n",
    "hidden_size = 100\n",
    "#net = FRNN_AS_SC(4, hidden_size, 4, device, 0.1, 0.15)\n",
    "net = FRNN_SC(4, hidden_size, 4, device, 0.1, 0.15)\n",
    "#net = TLRNN_AS_SC(4, hidden_size, device, 4, 0.1, 0.15)\n",
    "\n",
    "\n",
    "net.to(device)\n",
    "\n",
    "\n",
    "criterion = torch.nn.MSELoss(reduction='sum')\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=1e-3)\n",
    "epochs = 1000\n",
    "Losses = []\n",
    "Val_Losses = []\n",
    "\n",
    "\n",
    "for e in (range(epochs)):\n",
    "    epoch_loss = 0\n",
    "    epoch_val_loss = 0\n",
    "    for idx, batch in enumerate(dataloader):\n",
    "        batch = batch.to(device)\n",
    "        #Train step\n",
    "        out, loss = train_step(batch, hidden_size, net)\n",
    "        epoch_loss += loss\n",
    "        \n",
    "    for idx, batch in enumerate(dataloader_test):\n",
    "        batch = batch.to(device)\n",
    "        #Train step\n",
    "        out, loss = val_step(batch, hidden_size, net)\n",
    "        epoch_val_loss += loss\n",
    "    \n",
    "    Losses.append(epoch_loss/len(dataloader))\n",
    "    Val_Losses.append(epoch_val_loss/len(dataloader_test))\n",
    "\n",
    "    print(\"Loss: \", epoch_loss/len(dataloader))\n",
    "    print(\"Val Loss: \", epoch_val_loss/len(dataloader_test))\n",
    "\n",
    "\n",
    "    \n",
    "#Visualisation\n",
    "O, Y = val_step(batch, hidden_size, net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Losses_Frnn = Losses\n",
    "ValLosses_Frnn = Val_Losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Train_Loss\")\n",
    "plt.plot(Losses)\n",
    "plt.savefig(\"Train_Loss_Frnn.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.amin(Losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Val_Loss\")\n",
    "plt.plot(Val_Losses[:])\n",
    "plt.savefig(\"Val_Loss_Frnn.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.amin(Val_Losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmin(Val_Losses)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
